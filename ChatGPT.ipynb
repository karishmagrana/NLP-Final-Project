{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "API Reference:\n",
        "https://platform.openai.com/docs/api-reference/authentication"
      ],
      "metadata": {
        "id": "M0hQSDooLiEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzJceuEyOROK",
        "outputId": "ff23654b-6a2d-42d5-98a3-ab8ef475d4cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp28woXAJzPc",
        "outputId": "ebdda372-b61e-4122-a102-e732c40b3599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.5 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import csv"
      ],
      "metadata": {
        "id": "4KzBPsJ9Qdii"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_base_path = '/content/drive/MyDrive/'\n",
        "train_data = f'{dataset_base_path}translated_traindata.csv'\n",
        "val_data = f'{dataset_base_path}translated_valdata.csv'\n",
        "test_data_ORIGINAL = f'{dataset_base_path}translated_testdata.csv'\n",
        "test_sample_data_path = f'{dataset_base_path}project_test_data.csv'"
      ],
      "metadata": {
        "id": "XwXaUJvPQe9c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{dataset_base_path}release_evidences.json', 'r', encoding='utf-8') as f:\n",
        "    release_evidences = json.load(f)"
      ],
      "metadata": {
        "id": "bdCfHFw-Qsl9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_data, delimiter=None, \n",
        "                header='infer', names=None, \n",
        "                index_col=None, usecols=None, squeeze=False, \n",
        "                engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "val_df = pd.read_csv(val_data, delimiter=None, \n",
        "                header='infer', names=None, \n",
        "                index_col=None, usecols=None, squeeze=False, \n",
        "                engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "test_df = pd.read_csv(test_sample_data_path, delimiter=None,\n",
        "                header='infer', names=None, \n",
        "                index_col=None, usecols=None, squeeze=False, \n",
        "                engine='python', encoding='utf-8', error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgIMcnhfSxdy",
        "outputId": "65a1bc81-beba-4216-a59d-7926fb0bee3f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-be7cb27dcccd>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  train_df = pd.read_csv(train_data, delimiter=None,\n",
            "<ipython-input-6-be7cb27dcccd>:1: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
            "\n",
            "\n",
            "  train_df = pd.read_csv(train_data, delimiter=None,\n",
            "<ipython-input-6-be7cb27dcccd>:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  val_df = pd.read_csv(val_data, delimiter=None,\n",
            "<ipython-input-6-be7cb27dcccd>:5: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
            "\n",
            "\n",
            "  val_df = pd.read_csv(val_data, delimiter=None,\n",
            "<ipython-input-6-be7cb27dcccd>:9: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  test_df = pd.read_csv(test_sample_data_path, delimiter=None,\n",
            "<ipython-input-6-be7cb27dcccd>:9: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
            "\n",
            "\n",
            "  test_df = pd.read_csv(test_sample_data_path, delimiter=None,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import openai\n",
        "openai.api_key = os.getenv(API_KEY)\n",
        "models = openai.Model.list()"
      ],
      "metadata": {
        "id": "XanHFXRgLfWs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sample API Calls and Expected Output"
      ],
      "metadata": {
        "id": "nQgIVsqjQzGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": \"You are a doctor treating patients.\"},\n",
        "\n",
        "        {\"role\": \"user\", \"content\": \"What is a treatment for migraines?\"}\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "LDzuhf9kPk89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqVHY1A-SFs0",
        "outputId": "9a5f3c40-ea95-4c72-f2c6-ded489174759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"There are several treatment options for migraines such as:\\n\\n1. Pain-relieving medications such as over-the-counter (OTC) pain killers like aspirin or ibuprofen, or prescription medications like triptans, ergotamines, or opioids for more severe cases.\\n\\n2. Lifestyle changes which can include getting enough sleep, reducing stress, exercising regularly, avoiding food triggers, and tracking your symptoms.\\n\\n3. Complementary therapies such as acupuncture, massage therapy, and chiropractic treatment.\\n\\n4. Preventive medications such as beta-blockers, antidepressants, anticonvulsants, or Botox injections.\\n\\n5. Biofeedback, which is a technique used to help patients control their body's response to stress and prevent migraines.\\n\\nIt is important to consult with your doctor to determine the best treatment option for your migraine.\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1682121958,\n",
            "  \"id\": \"chatcmpl-77v3GHG3bkFzVuAt0Si6eL0rfsbSj\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 167,\n",
            "    \"prompt_tokens\": 27,\n",
            "    \"total_tokens\": 194\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2 = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": \"You are a doctor treating patients\"},\n",
        "        {\"role\": \"system\", \"content\": \"What should I prescribe to a patient with migraines?\"}\n",
        "        ],\n",
        "    max_tokens=15,\n",
        "    temperature=0)"
      ],
      "metadata": {
        "id": "OwbJHuxBSdk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcASjamhTU2S",
        "outputId": "77be3c2d-eaa3-47a1-81ce-b1df6c35782d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"As an AI language model, I cannot diagnose or prescribe medication. However,\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1682122294,\n",
            "  \"id\": \"chatcmpl-77v8gxQmYhZ0ZNmdAnRTiWMBTgWFp\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 15,\n",
            "    \"prompt_tokens\": 30,\n",
            "    \"total_tokens\": 45\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Given these questions and answers, can you diagnose the patient by giving the ICD10 code? Do not give an explanation or any context, just the most likely ICD10 code: {'Do you have a poor diet?': 'True', 'Have you ever had a diagnosis of anemia?': 'True', 'Do you have any family members who have been diagnosed with anemia?': 'True', 'Do you have pain somewhere, related to your reason for consulting?': 'True', 'Characterize your pain:': 'a cramp', 'Do you feel pain somewhere?': 'temple(L)', 'How intense is the pain?': '2', 'Does the pain radiate to another location?': 'nowhere', 'How precisely is the pain located?': '3', 'How fast did the pain appear?': '5', 'Do you feel slightly dizzy or lightheaded?': 'True', 'Do you feel lightheaded and dizzy or do you feel like you are about to faint?': 'True', 'Do you feel so tired that you are unable to do your usual activities or are you stuck in your bed all day long?': 'True', 'Do you constantly feel fatigued or do you have non-restful sleep?': 'True', 'Do you have chronic kidney failure?': 'True', 'Have you recently had stools that were black (like coal)?': 'True', 'Are you taking any new oral anticoagulants ((NOACs)?': 'True', 'Is your skin much paler than usual?': 'True', 'Have you traveled out of the country in the last 4 weeks?': 'South East Asia', 'Is your BMI less than 18.5, or are you underweight?': 'True'}\" \n",
        "response3 = openai.ChatCompletion.create(\n",
        "    model='gpt-3.5-turbo',\n",
        "    messages=[\n",
        "        {\"role\":\"system\", \"content\": \"You are a doctor diagnosing patients\"},\n",
        "        {\"role\":\"user\", \"content\": question}\n",
        "        ],\n",
        "    max_tokens=5,\n",
        "    temperature=0)"
      ],
      "metadata": {
        "id": "xL99I7eQUUTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7esL60bU3Bh",
        "outputId": "da46bdd5-d8e0-43b9-d7f9-2676d13d9510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"length\",\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"content\": \"D50.9 -\",\n",
            "        \"role\": \"assistant\"\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1682122723,\n",
            "  \"id\": \"chatcmpl-77vFbMeFpB3JM6nmO6cEns08iXYTB\",\n",
            "  \"model\": \"gpt-3.5-turbo-0301\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 5,\n",
            "    \"prompt_tokens\": 394,\n",
            "    \"total_tokens\": 399\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test ChatGPT without Finetuning"
      ],
      "metadata": {
        "id": "SK5uQU20Qp19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generateResponse(question, datapoint, maxTokens, temperature):\n",
        "  try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "      model='gpt-3.5-turbo',\n",
        "      messages=[\n",
        "          {\"role\":\"system\", \"content\": \"You are a doctor diagnosing patients\"},\n",
        "          {\"role\":\"user\", \"content\": question}\n",
        "          ],\n",
        "      max_tokens= maxTokens,\n",
        "      temperature= temperature)\n",
        "    response[\"dataPoint\"] = datapoint\n",
        "    response[\"inputPrompt\"] = question\n",
        "    return response\n",
        "  except:\n",
        "    print(f'Error occurred with API for datapoint {datapoint}')\n",
        "    print(\"Terminating\")"
      ],
      "metadata": {
        "id": "l-Y0dYixke02"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data should be a dict such as {\"responses\" : out}\n",
        "def writeOutput(filePath, data):\n",
        "  if type(data) == list:\n",
        "    data = {\"responses\" : data}\n",
        "  with open(filePath, 'w') as outfile:\n",
        "    json.dump(data, outfile)"
      ],
      "metadata": {
        "id": "qxw0lI9-lrTp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readJSONFile(filePath):\n",
        "  f = open(filePath)\n",
        "  data = json.load(f)\n",
        "  return data #dictionary mapping to a list of ChatGPT API responses"
      ],
      "metadata": {
        "id": "i2sitmT7mAtK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createPrompt(age, gender, questions):\n",
        "  if type(age) == str:\n",
        "    assert(age.isdigit())\n",
        " \n",
        "  if gender == \"M\":\n",
        "    gender = \"male\"\n",
        "  elif gender == \"F\":\n",
        "    gender = \"female\"\n",
        "  else:\n",
        "    print(\"Unexpected gender input\")\n",
        "\n",
        "  basePrompt = f'Diagnose a {age} year-old {gender} patient by giving the ICD-10 code. Do not give an explanation or any context. Your response should be one token with the ICD-10 code: '\n",
        "  prompt = basePrompt + questions\n",
        "  return prompt\n",
        "\n",
        "#QandA = \"{'Do you have a poor diet?': 'True', 'Have you ever had a diagnosis of anemia?': 'True', 'Do you have any family members who have been diagnosed with anemia?': 'True', 'Do you have pain somewhere, related to your reason for consulting?': 'True', 'Characterize your pain:': 'a cramp', 'Do you feel pain somewhere?': 'temple(L)', 'How intense is the pain?': '2', 'Does the pain radiate to another location?': 'nowhere', 'How precisely is the pain located?': '3', 'How fast did the pain appear?': '5', 'Do you feel slightly dizzy or lightheaded?': 'True', 'Do you feel lightheaded and dizzy or do you feel like you are about to faint?': 'True', 'Do you feel so tired that you are unable to do your usual activities or are you stuck in your bed all day long?': 'True', 'Do you constantly feel fatigued or do you have non-restful sleep?': 'True', 'Do you have chronic kidney failure?': 'True', 'Have you recently had stools that were black (like coal)?': 'True', 'Are you taking any new oral anticoagulants ((NOACs)?': 'True', 'Is your skin much paler than usual?': 'True', 'Have you traveled out of the country in the last 4 weeks?': 'South East Asia', 'Is your BMI less than 18.5, or are you underweight?': 'True'}\" \n",
        "#prompt = createPrompt(\"37\", 'F', QandA)"
      ],
      "metadata": {
        "id": "DOxkDYelnvpX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatGPTOutput = []\n",
        "i = 0\n",
        "temp = test_df.iterrows()\n",
        "batchNum = 1\n",
        "tempDF = test_df.iloc[batchNum*1000:batchNum*1000+1000, :] \n",
        "for index, row in tempDF.iterrows():\n",
        "    if i % 100 == 0:\n",
        "      print(f'Question {i} asked')\n",
        "    age = row['AGE']\n",
        "    gender = row['SEX']\n",
        "    questionDict = row['English Evidences']\n",
        "    ICD10val = row['ICD-10']\n",
        "    originalRowKey = row[\"OriginalRowKey\"]\n",
        "    prompt = createPrompt(age, gender, questionDict)\n",
        "    response = generateResponse(prompt, originalRowKey, 5, .05)\n",
        "    chatGPTOutput.append(response)\n",
        "    i = i + 1\n"
      ],
      "metadata": {
        "id": "lLCmJixAtuMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e007843-aa7d-4d5f-91ad-33bfe958fe7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 0 asked\n",
            "Question 100 asked\n",
            "Question 200 asked\n",
            "Question 300 asked\n",
            "Question 400 asked\n",
            "Question 500 asked\n",
            "Question 600 asked\n",
            "Question 700 asked\n",
            "Question 800 asked\n",
            "Question 900 asked\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filePathToStoreOutput = f'/content/drive/MyDrive/chatGPTBatch{batchNum}.json'\n",
        "writeOutput(filePathToStoreOutput, chatGPTOutput)"
      ],
      "metadata": {
        "id": "p5fckQ7tbTCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = f'/content/drive/MyDrive/chatGPTBatch{batchNum}.json'\n",
        "data = readJSONFile(filePath)\n",
        "chatGPTResponses= data['responses']\n",
        "print(len(chatGPTResponses))\n",
        "for dataDict in chatGPTResponses:\n",
        "  if dataDict:\n",
        "    inputPrompt = dataDict['inputPrompt']\n",
        "    response = dataDict['choices'][0]['message']['content']\n",
        "    rowKey = dataDict['dataPoint']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4RNFJu91izo",
        "outputId": "a6d3e72a-c691-4bd8-b68e-82e4345d61b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chat GPT with Few Shot Learning"
      ],
      "metadata": {
        "id": "QczuKKjUSM0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fewShotDataPath = f'{dataset_base_path}Project_Train_Data_FewShot_Learning_588samples.csv'\n",
        "fewShotDatadf = pd.read_csv(fewShotDataPath, delimiter=None,\n",
        "                header='infer', names=None, \n",
        "                index_col=None, usecols=None, squeeze=False, \n",
        "                engine='python', encoding='utf-8', error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJrtQebZd9VK",
        "outputId": "1eb55f44-c370-4328-9eea-736651a73c4d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-749aa8a03efc>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  fewShotDatadf = pd.read_csv(fewShotDataPath, delimiter=None,\n",
            "<ipython-input-14-749aa8a03efc>:2: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
            "\n",
            "\n",
            "  fewShotDatadf = pd.read_csv(fewShotDataPath, delimiter=None,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createPrompt(age, gender, questions):\n",
        "  if type(age) == str:\n",
        "    assert(age.isdigit())\n",
        " \n",
        "  if gender == \"M\":\n",
        "    gender = \"male\"\n",
        "  elif gender == \"F\":\n",
        "    gender = \"female\"\n",
        "  else:\n",
        "    print(\"Unexpected gender input\")\n",
        "\n",
        "  basePrompt = f'Diagnose a {age} year-old {gender} patient by giving the ICD-10 code. Do not give an explanation or any context. Your response should be one token with the ICD-10 code: '\n",
        "  prompt = basePrompt + questions\n",
        "  return prompt\n",
        "\n",
        "#QandA = \"{'Do you have a poor diet?': 'True', 'Have you ever had a diagnosis of anemia?': 'True', 'Do you have any family members who have been diagnosed with anemia?': 'True', 'Do you have pain somewhere, related to your reason for consulting?': 'True', 'Characterize your pain:': 'a cramp', 'Do you feel pain somewhere?': 'temple(L)', 'How intense is the pain?': '2', 'Does the pain radiate to another location?': 'nowhere', 'How precisely is the pain located?': '3', 'How fast did the pain appear?': '5', 'Do you feel slightly dizzy or lightheaded?': 'True', 'Do you feel lightheaded and dizzy or do you feel like you are about to faint?': 'True', 'Do you feel so tired that you are unable to do your usual activities or are you stuck in your bed all day long?': 'True', 'Do you constantly feel fatigued or do you have non-restful sleep?': 'True', 'Do you have chronic kidney failure?': 'True', 'Have you recently had stools that were black (like coal)?': 'True', 'Are you taking any new oral anticoagulants ((NOACs)?': 'True', 'Is your skin much paler than usual?': 'True', 'Have you traveled out of the country in the last 4 weeks?': 'South East Asia', 'Is your BMI less than 18.5, or are you underweight?': 'True'}\" \n",
        "#prompt = createPrompt(\"37\", 'F', QandA)"
      ],
      "metadata": {
        "id": "E3NKFiaXegvp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = []\n",
        "for index, row in fewShotDatadf.iterrows():\n",
        "    age = row['AGE']\n",
        "    gender = row['SEX']\n",
        "    questionDict = row['English Evidences']\n",
        "    ICD10val = row['ICD-10']\n",
        "    originalRowKey = row[\"OriginalRowKey\"]\n",
        "    prompt = createPrompt(age, gender, questionDict)\n",
        "    dictionary = {\"prompt\": prompt, \"completion\": ICD10val}\n",
        "    output.append(dictionary)"
      ],
      "metadata": {
        "id": "_y1GeC8HgVmZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fewShotFilePath = f'{dataset_base_path}fewShotSamples.json'\n",
        "print(fewShotFilePath)\n",
        "with open(fewShotFilePath, 'w') as outfile:\n",
        "    json.dump(output, outfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUkv-enqheJL",
        "outputId": "fb35a85a-2a00-4d0f-9167-70e03fab6415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/fewShotSamples.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data to pass into davinci finetune\n",
        "#!openai tools fine_tunes.prepare_data -f /content/drive/MyDrive/fewShotSamples.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot1WXJSUeqrN",
        "outputId": "67dc2630-0911-4c1d-85f8-1cbe7221930e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 588 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- All prompts end with suffix `'}`\n",
            "- All prompts start with prefix `Diagnose a `\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified files to `/content/drive/MyDrive/fewShotSamples_prepared_train (1).jsonl` and `/content/drive/MyDrive/fewShotSamples_prepared_valid (1).jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"/content/drive/MyDrive/fewShotSamples_prepared_train (1).jsonl\" -v \"/content/drive/MyDrive/fewShotSamples_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_n_classes 49\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `'}` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 16.45 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code below creates finetuned model\n",
        "#!openai api fine_tunes.create -t /content/drive/MyDrive/fewShotSamples_prepared_train.jsonl -v /content/drive/MyDrive/fewShotSamples_prepared_valid.jsonl --batch_size 12 -m davinci"
      ],
      "metadata": {
        "id": "Vajna8lhnEHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.get -i ft-7ZohxTose4nSMJinsTi8OiCH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvcT3d3RrI_6",
        "outputId": "6d9f1b3e-f6a8-4094-d15e-690a488016ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"created_at\": 1682363407,\n",
            "  \"events\": [\n",
            "    {\n",
            "      \"created_at\": 1682363407,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Created fine-tune: ft-7ZohxTose4nSMJinsTi8OiCH\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363439,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune costs $15.77\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363439,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune enqueued. Queue number: 0\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363444,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune started\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363634,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Completed epoch 1/4\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363726,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Completed epoch 2/4\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363819,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Completed epoch 3/4\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363915,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Completed epoch 4/4\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363955,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Uploaded model: davinci:ft-personal-2023-04-24-19-19-14\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363956,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Uploaded result file: file-fVGqf4O86bDkbfSVTdG4MUB9\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    },\n",
            "    {\n",
            "      \"created_at\": 1682363956,\n",
            "      \"level\": \"info\",\n",
            "      \"message\": \"Fine-tune succeeded\",\n",
            "      \"object\": \"fine-tune-event\"\n",
            "    }\n",
            "  ],\n",
            "  \"fine_tuned_model\": \"davinci:ft-personal-2023-04-24-19-19-14\",\n",
            "  \"hyperparams\": {\n",
            "    \"batch_size\": 12,\n",
            "    \"learning_rate_multiplier\": 0.1,\n",
            "    \"n_epochs\": 4,\n",
            "    \"prompt_loss_weight\": 0.01\n",
            "  },\n",
            "  \"id\": \"ft-7ZohxTose4nSMJinsTi8OiCH\",\n",
            "  \"model\": \"davinci\",\n",
            "  \"object\": \"fine-tune\",\n",
            "  \"organization_id\": \"org-Sa7rIQxqNeFjTv0DLtWWrB5u\",\n",
            "  \"result_files\": [\n",
            "    {\n",
            "      \"bytes\": 11249,\n",
            "      \"created_at\": 1682363956,\n",
            "      \"filename\": \"compiled_results.csv\",\n",
            "      \"id\": \"file-fVGqf4O86bDkbfSVTdG4MUB9\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"training_files\": [\n",
            "    {\n",
            "      \"bytes\": 505135,\n",
            "      \"created_at\": 1682363405,\n",
            "      \"filename\": \"/content/drive/MyDrive/fewShotSamples_prepared_train.jsonl\",\n",
            "      \"id\": \"file-AndlLYuTzXonFEUABDjehtrC\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"updated_at\": 1682363956,\n",
            "  \"validation_files\": [\n",
            "    {\n",
            "      \"bytes\": 124697,\n",
            "      \"created_at\": 1682363407,\n",
            "      \"filename\": \"/content/drive/MyDrive/fewShotSamples_prepared_valid.jsonl\",\n",
            "      \"id\": \"file-iB5v2jATU3NRAcuV3TdiqW4v\",\n",
            "      \"object\": \"file\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run code below in terminal to see results of training/validation\n",
        "curl https://api.openai.com/v1/files/file-fVGqf4O86bDkbfSVTdG4MUB9/content -H \"Authorization: Bearer {APIKEY}\" > results.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JsdQ9UNyDnN",
        "outputId": "9ae545b0-4fa7-42ca-fbfa-6ad00b5d3d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mError:\u001b[0m No fine-tune job: file-fVGqf4O86bDkbfSVTdG4MUB9 (HTTP status code: 404)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateFineTunedResponse(question, datapoint, maxTokens, temperature):\n",
        "  try:\n",
        "    response = openai.Completion.create(\n",
        "      model='davinci:ft-personal-2023-04-24-19-19-14',\n",
        "      prompt = question,\n",
        "      max_tokens= maxTokens,\n",
        "      temperature= temperature)\n",
        "    response[\"dataPoint\"] = datapoint\n",
        "    response[\"inputPrompt\"] = question\n",
        "    return response\n",
        "  except:\n",
        "    print(f'Error occurred with API for datapoint {datapoint}')\n",
        "    print(\"Terminating\")"
      ],
      "metadata": {
        "id": "_fMW0GTQe-Ym"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatGPTOutput = []\n",
        "i = 0\n",
        "temp = test_df.iterrows()\n",
        "batchNum = 1\n",
        "tempDF = test_df.iloc[batchNum*1000:batchNum*1000 + 1000, :]\n",
        "for index, row in tempDF.iterrows():\n",
        "    if i % 100 == 0:\n",
        "      print(f'Question {i} asked')\n",
        "    age = row['AGE']\n",
        "    gender = row['SEX']\n",
        "    questionDict = row['English Evidences']\n",
        "    ICD10val = row['ICD-10']\n",
        "    originalRowKey = row[\"OriginalRowKey\"]\n",
        "    #print(originalRowKey)\n",
        "    #print(row['AGE'], row['SEX'], row['English Evidences'])\n",
        "    #prompt = createPrompt(age, gender, questionDict)\n",
        "    response = generateFineTunedResponse(prompt, originalRowKey, 5, .05)\n",
        "    #print(f'Response is {response}')\n",
        "    #print(prompt)\n",
        "    chatGPTOutput.append(response)\n",
        "    i = i + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCsGU4D7fYvm",
        "outputId": "9b139900-41eb-477c-d6d3-a3e14e847301"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question 0 asked\n",
            "Question 100 asked\n",
            "Question 200 asked\n",
            "Question 300 asked\n",
            "Question 400 asked\n",
            "Question 500 asked\n",
            "Question 600 asked\n",
            "Question 700 asked\n",
            "Question 800 asked\n",
            "Question 900 asked\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fineTunedFilePath = f'/content/drive/MyDrive/DavinciBatch{batchNum}.json'"
      ],
      "metadata": {
        "id": "bbVmE50Rg2Pt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePathToStoreOutput = fineTunedFilePath\n",
        "writeOutput(filePathToStoreOutput, chatGPTOutput)"
      ],
      "metadata": {
        "id": "TMfzGdahSULf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filePath = fineTunedFilePath\n",
        "data = readJSONFile(filePath)\n",
        "chatGPTResponses= data['responses']\n",
        "print(len(chatGPTResponses))\n",
        "tokens = []\n",
        "for dataDict in chatGPTResponses:\n",
        "  if dataDict:\n",
        "    #print(dataDict)\n",
        "    inputPrompt = dataDict['inputPrompt']\n",
        "    response = dataDict['choices'][0]['text']\n",
        "    tokens.append(dataDict['usage']['total_tokens'])\n",
        "    #' j4.9'\n",
        "    rowKey = dataDict['dataPoint']\n",
        "\n",
        "avgToken = sum(tokens)/len(tokens)\n",
        "#davinciCost = .12/1k tokens\n",
        "numOfPromptsPer1k = (1000/298.228)\n",
        "ratio = (1000/numOfPromptsPer1k)\n",
        "totalCost = .12 * ratio\n",
        "print(totalCost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usw3VzTKfS24",
        "outputId": "4fb4159d-056a-4b5f-cede-9ba174dd623a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "35.78736\n"
          ]
        }
      ]
    }
  ]
}